{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('cal_housing with header.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_relation=df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr_features = co_relation.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n",
    "print(top_corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:n-1]\n",
    "y=df.iloc[:,n-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(9).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions=lr.predict(X_test)\n",
    "lr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot(y_test-lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, lr_predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, lr_predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, lr_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_joblib_file = \"VK_lr_model_CV.pkl\"  \n",
    "joblib.dump(lr, lr_joblib_file)\n",
    "# dump information to that file\n",
    "#pickle.dump(rf_random, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = linear_model.RidgeCV(alphas=[0.1,0.2,0.3,0.4,0.5,0.9, 1.0,2,3,4,5,6, 10.0], cv=3, fit_intercept=True, scoring=None, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rr = Ridge(alpha=1)\n",
    "rr.fit(X_train, y_train) \n",
    "pred_train_rr= rr.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_rr)))\n",
    "print(r2_score(y_train, pred_train_rr))\n",
    "rr_predictions= rr.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,rr_predictions))) \n",
    "print(r2_score(y_test, rr_predictions))\n",
    "print(rr_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = Ridge(alpha=3)\n",
    "rr.fit(X_train, y_train) \n",
    "pred_train_rr= rr.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_rr)))\n",
    "print(r2_score(y_train, pred_train_rr))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rr_predictions= rr.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,rr_predictions))) \n",
    "print(r2_score(y_test, rr_predictions))\n",
    "print(rr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rr = Ridge(alpha=1)\n",
    "rr.fit(X_train, y_train) \n",
    "pred_train_rr= rr.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_rr)))\n",
    "print(r2_score(y_train, pred_train_rr))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rr_predictions= rr.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,rr_predictions))) \n",
    "print(r2_score(y_test, rr_predictions))\n",
    "print(rr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, rr_predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, rr_predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, rr_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib_file = \"VK_RR_Model_CV.pkl\"  \n",
    "joblib.dump(rr, joblib_file)\n",
    "# dump information to that file\n",
    "#pickle.dump(rf_random, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = Lasso(alpha=1)\n",
    "model_lasso.fit(X_train, y_train) \n",
    "pred_train_lasso= model_lasso.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_lasso)))\n",
    "print(r2_score(y_train, pred_train_lasso))\n",
    "\n",
    "lasso_predictions= model_lasso.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,lasso_predictions))) \n",
    "print(r2_score(y_test, lasso_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, lasso_predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, lasso_predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, lasso_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib_file = \"VK_LASSO_Model_CV.pkl\"  \n",
    "joblib.dump(model_lasso, joblib_file)\n",
    "# dump information to that file\n",
    "#pickle.dump(rf_random, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELASTC NET REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_enet = ElasticNet(alpha = 0.01)\n",
    "model_enet.fit(X_train, y_train) \n",
    "pred_train_enet= model_enet.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_enet)))\n",
    "print(r2_score(y_train, pred_train_enet))\n",
    "\n",
    "ELASTIC_predictions= model_enet.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,ELASTIC_predictions)))\n",
    "print(r2_score(y_test, ELASTIC_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, ELASTIC_predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, ELASTIC_predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, ELASTIC_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib_file = \"VK_ELASTIC_Model_CV.pkl\"  \n",
    "joblib.dump(model_enet, joblib_file)\n",
    "# dump information to that file\n",
    "#pickle.dump(rf_random, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
